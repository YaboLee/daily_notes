> Yesterday is history, tomorrow is a mystery, but today is a gift. That is why it is called the  present.
>
> ---- Kung Fu Panda



# JSON syntax

JSON requires double quotes for its string. In this case, string with single quotes will not be recognized.

In Python, usually we use json.loads() to load json structure file.

```python
import json
from pprint import pprint
f = open(file)
line = f.readline()
json_line = json.loads(line)
pprint(json_line) # structured print
```

Instead, we need to find something to replace json.

```python
import ast
from pprint import pprint
f = open(file)
line = f.readline()
json_line = ast.literal_eval(line) # ast can recognize single quoted string
pprint(json_line) # structured print
```



**Case:** When using pyspark, output file are saved as single quoted string. We cannot load them again with json.



# Spark

Input path can be a directory or multi-files.

```python
spark-submit --master --deploy-mode client script.py file://path_to_dir/ file://path_to_output

spark-submit --master --deploy-mode client script.py file://path_to_dir/part-000* file://path_to_output
```



# HDFS

Some useful commands.

```bash
hdfs dfs -ls # list
hdfs dfs -ls -h # -h is humanized, display size in humanized way
hdfs dfs -tail # show last couple of lines of a file
hdfs dfs -count -h [file] # count the size of file in humanized way
hdfs dfs -cat [file] # cat the content; warning: Don't use when the file is large
hdfs dfs -ls [dir] | wc -l # total # of files
hdfs dfs -cat [file] | wc -l # total # of lines of a file

hdfs dfs -mkdir [dir] # create a dir
hdfs dfs -rm [file] # delete file
hdfs dfs -rm -r [dir] #delete dir

hdfs dfs -copyFromLocal [file] [dir_to_hdfs]
```

